Help me diagnose, root cause analysis and solve: INFO:     Started server process [57596]
INFO:     Waiting for application startup.
INFO:api_service.main:Starting up API service...
INFO:api_service.main:Initializing database...
INFO:api_service.main:Database initialized successfully
2026/02/18 21:24:17 INFO mlflow.tracking.fluent: Experiment with name 'protocol-processing' does not exist. Creating a new experiment.
INFO:api_service.main:MLflow LangChain autolog enabled
INFO:api_service.main:MLflow initialized: tracking_uri=http://localhost:5001, experiment=protocol-processing
INFO:events_py.outbox:Outbox processor started (interval=1.0s, batch_size=100)
INFO:     Application startup complete.
INFO:     127.0.0.1:52068 - "GET /health HTTP/1.1" 200 OK
INFO:     127.0.0.1:52069 - "GET /reviews/audit-log?page=1&page_size=20 HTTP/1.1" 200 OK
INFO:     127.0.0.1:52067 - "GET /reviews/pending-summary HTTP/1.1" 200 OK
INFO:     127.0.0.1:52067 - "GET /protocols?page=1&page_size=20&deduplicate=true HTTP/1.1" 200 OK
INFO:api_service.gcs:Local storage: upload URL for Prot_000-a90aedda.pdf -> local://cb6e58bd-27d4-45b7-912f-d5c6dc1f6b2c/Prot_000-a90aedda.pdf
INFO:     127.0.0.1:52071 - "POST /protocols/upload HTTP/1.1" 200 OK
INFO:protocol_processor.trigger:Handling ProtocolUploaded event for protocol be62cb3c-4691-4898-9178-43d090467dbf (consolidated pipeline)
ERROR:protocol_processor.nodes.ingest:Ingestion failed for protocol be62cb3c-4691-4898-9178-43d090467dbf: Local PDF not found at REDACTED.pdf. Ensure LOCAL_UPLOAD_DIR is set correctly (current: uploads/protocols) and the file has been uploaded. If the API runs in Docker with a volume mount, set LOCAL_UPLOAD_DIR to the mounted host path.
Traceback (most recent call last):
  File "/Users/noahdolevelixir/Code/medgemma-hackathon/services/protocol-processor-service/src/protocol_processor/nodes/ingest.py", line 51, in ingest_node
    pdf_bytes = await fetch_pdf_bytes(state["file_uri"])
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/noahdolevelixir/Code/medgemma-hackathon/services/protocol-processor-service/src/protocol_processor/tools/pdf_parser.py", line 83, in fetch_pdf_bytes
    raise FileNotFoundError(
FileNotFoundError: Local PDF not found at REDACTED.pdf. Ensure LOCAL_UPLOAD_DIR is set correctly (current: uploads/protocols) and the file has been uploaded. If the API runs in Docker with a volume mount, set LOCAL_UPLOAD_DIR to the mounted host path.
2026/02/18 21:24:35 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during autologging: <Token var=<ContextVar name='current_context' default={} at 0x10b788d10> at 0x12b4c3340> was created in a different Context
2026/02/18 21:24:35 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during autologging: <Token var=<ContextVar name='current_context' default={} at 0x10b788d10> at 0x12b63d100> was created in a different Context
2026/02/18 21:24:35 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during autologging: <Token var=<ContextVar name='current_context' default={} at 0x10b788d10> at 0x12b5f6a00> was created in a different Context
INFO:protocol_processor.trigger:Protocol pipeline completed for protocol be62cb3c-4691-4898-9178-43d090467dbf
INFO:events_py.outbox:Published event 6ae9951a-483d-4afb-a6bf-d22d9a3feada (type=protocol_uploaded)
INFO:events_py.outbox:Processed 1 outbox events

---

Let's test your hypothesis and then implement the best practices fix (which you can research if you need to)

---

Now I don't see an error but we are stuck uploading forever even for tiny pdf's

---

This is taking forever.

---

[Request interrupted by user for tool use]

---

<task-notification>
<task-id>bb6d138</task-id>
<output-file>REDACTED.output</output-file>
<status>failed</status>
<summary>Background command "curl -s -X POST http://localhost:8000/protocols/upload -H "Content-Type: application/json" -d '{"filename":"test.pdf","content_type":"application/pdf","file_size_bytes":1024}' 2>&1" failed with exit code 56</summary>
</task-notification>
Read the output file to retrieve the result: REDACTED.output

---

I just tried to upload a pdf and I got "Failed to fetch" and I see this in the console: Failed to fetch

---

[Request interrupted by user]

---

I just tried to upload a pdf and I got "Failed to fetch" and I see this in the console: client:789 [vite] connecting...
client:912 [vite] connected.
:8000/local-upload/5ca1c119-55f0-4f2d-a108-dad1fda60e56/Prot_000-e06adb27.pdf:1  Failed to load resource: net::ERR_CONNECTION_REFUSED

---

Can you diagnose, root cause analyze then plan a solution to these warnings and errors:
INFO:protocol_processor.trigger:Handling ProtocolUploaded event for protocol 0c49aad8-36a7-4e84-920e-4ad9e360bf41 (consolidated pipeline)
INFO:protocol_processor.tools.pdf_parser:Reading PDF from local path: REDACTED.pdf
INFO:protocol_processor.nodes.ingest:Ingested protocol 0c49aad8-36a7-4e84-920e-4ad9e360bf41: 788298 bytes of PDF
2026/02/18 21:59:18 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during autologging: <Token var=<ContextVar name='current_context' default={} at 0x10d529710> at 0x12b93dfc0> was created in a different Context
INFO:     127.0.0.1:60756 - "OPTIONS /protocols/0c49aad8-36a7-4e84-920e-4ad9e360bf41 HTTP/1.1" 200 OK
2026/02/18 21:59:18 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during autologging: <Token var=<ContextVar name='current_context' default={} at 0x10d529710> at 0x12d43d840> was created in a different Context
INFO:     127.0.0.1:60820 - "OPTIONS /reviews/batches?protocol_id=0c49aad8-36a7-4e84-920e-4ad9e360bf41 HTTP/1.1" 200 OK
INFO:     127.0.0.1:60756 - "GET /protocols/0c49aad8-36a7-4e84-920e-4ad9e360bf41 HTTP/1.1" 200 OK
INFO:     127.0.0.1:60871 - "GET /reviews/batches?protocol_id=0c49aad8-36a7-4e84-920e-4ad9e360bf41 HTTP/1.1" 200 OK
INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?REDACTED&upload_protocol=resumable "HTTP/1.1 200 OK"
INFO:google_genai.models:AFC is enabled with max remote calls: 10.
/Users/noahdolevelixir/Code/medgemma-hackathon/.venv/lib/python3.12/site-packages/google/genai/_api_client.py:755: DeprecationWarning: Inheritance class AiohttpClientSession from ClientSession is discouraged
  class AiohttpClientSession(aiohttp.ClientSession):  # type: ignore[misc]

---

are we using the latest google genAi package? Can you research to make sure there isn't already a fix to the mlflow issue or better way to log traces to avoid the warning?

---

No, I want to use claude login because I have a subscription

---

[Request interrupted by user for tool use]

---

Don't use playwright to browse the web - use fetch or context7

---

The issue is we are using mlflow in a docker

---

That's okay for dev but not for prod. When we ultimately want to deploy this app we'll want to have the MLFlow server running so we can follow any issues. Make a GSD plan for this enhancement.

---

[Request interrupted by user for tool use]