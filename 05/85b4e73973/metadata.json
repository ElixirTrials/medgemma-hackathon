{
  "cli_version": "0.4.5",
  "checkpoint_id": "0585b4e73973",
  "strategy": "manual-commit",
  "branch": "feature/perf-test-limits-and-async-grounding",
  "checkpoints_count": 1,
  "files_touched": [
    "services/protocol-processor-service/src/protocol_processor/tools/field_mapper.py",
    "services/protocol-processor-service/src/protocol_processor/tools/medgemma_decider.py",
    "services/protocol-processor-service/src/protocol_processor/tools/ordinal_resolver.py",
    "services/protocol-processor-service/src/protocol_processor/tools/structure_builder.py",
    "services/protocol-processor-service/tests/test_ordinal_full_cycle.py",
    "services/protocol-processor-service/tests/test_ordinal_resolve.py",
    "services/protocol-processor-service/tests/test_phase1b_wiring.py",
    "services/protocol-processor-service/tests/test_phase2_structure.py"
  ],
  "sessions": [
    {
      "metadata": "/05/85b4e73973/0/metadata.json",
      "transcript": "/05/85b4e73973/0/full.jsonl",
      "context": "/05/85b4e73973/0/context.md",
      "content_hash": "/05/85b4e73973/0/content_hash.txt",
      "prompt": "/05/85b4e73973/0/prompt.txt"
    },
    {
      "metadata": "/05/85b4e73973/1/metadata.json",
      "transcript": "/05/85b4e73973/1/full.jsonl",
      "context": "/05/85b4e73973/1/context.md",
      "content_hash": "/05/85b4e73973/1/content_hash.txt",
      "prompt": "/05/85b4e73973/1/prompt.txt"
    },
    {
      "metadata": "/05/85b4e73973/2/metadata.json",
      "transcript": "/05/85b4e73973/2/full.jsonl",
      "context": "/05/85b4e73973/2/context.md",
      "content_hash": "/05/85b4e73973/2/content_hash.txt",
      "prompt": "/05/85b4e73973/2/prompt.txt"
    },
    {
      "metadata": "/05/85b4e73973/3/metadata.json",
      "transcript": "/05/85b4e73973/3/full.jsonl",
      "context": "/05/85b4e73973/3/context.md",
      "content_hash": "/05/85b4e73973/3/content_hash.txt",
      "prompt": "/05/85b4e73973/3/prompt.txt"
    },
    {
      "metadata": "/05/85b4e73973/4/metadata.json",
      "transcript": "/05/85b4e73973/4/full.jsonl",
      "context": "/05/85b4e73973/4/context.md",
      "content_hash": "/05/85b4e73973/4/content_hash.txt",
      "prompt": "/05/85b4e73973/4/prompt.txt"
    }
  ],
  "token_usage": {
    "input_tokens": 10915,
    "cache_creation_tokens": 997542,
    "cache_read_tokens": 53002796,
    "output_tokens": 69450,
    "api_call_count": 534
  }
}
