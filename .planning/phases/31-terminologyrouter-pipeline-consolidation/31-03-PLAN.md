---
phase: 31-terminologyrouter-pipeline-consolidation
plan: 03
type: execute
wave: 2
depends_on: ["31-01", "31-02"]
files_modified:
  - services/protocol-processor-service/src/protocol_processor/nodes/ground.py
  - services/protocol-processor-service/src/protocol_processor/nodes/persist.py
  - services/protocol-processor-service/src/protocol_processor/tools/medgemma_decider.py
  - services/protocol-processor-service/src/protocol_processor/tools/field_mapper.py
  - services/protocol-processor-service/src/protocol_processor/prompts/grounding_system.jinja2
  - services/protocol-processor-service/src/protocol_processor/prompts/grounding_evaluate.jinja2
  - services/protocol-processor-service/src/protocol_processor/graph.py
  - services/protocol-processor-service/src/protocol_processor/trigger.py
  - services/protocol-processor-service/src/protocol_processor/main.py
  - services/api-service/src/api_service/main.py
  - services/protocol-processor-service/tests/test_graph.py
autonomous: true

must_haves:
  truths:
    - "Ground node routes entities via TerminologyRouter and delegates to MedGemma for best-match selection"
    - "Errors accumulate — partial entity failures do not fail entire batch"
    - "All agent exchanges (MedGemma decisions, API calls, routing) are logged to AuditLog"
    - "Persist node commits grounding results and updates protocol status to pending_review"
    - "5-node graph compiles and routes: ingest→extract→parse→ground→persist with conditional error routing"
    - "Pipeline is triggered by protocol_uploaded outbox event (criteria_extracted removed)"
    - "Field mappings are generated during grounding per user decision"
  artifacts:
    - path: "services/protocol-processor-service/src/protocol_processor/nodes/ground.py"
      provides: "Entity grounding node with TerminologyRouter + MedGemma"
      contains: "async def ground_node"
    - path: "services/protocol-processor-service/src/protocol_processor/nodes/persist.py"
      provides: "Final persistence node"
      contains: "async def persist_node"
    - path: "services/protocol-processor-service/src/protocol_processor/tools/medgemma_decider.py"
      provides: "MedGemma decision tool for best-match selection"
      contains: "async def medgemma_decide"
    - path: "services/protocol-processor-service/src/protocol_processor/tools/field_mapper.py"
      provides: "Field mapping generation tool"
      contains: "async def generate_field_mappings"
    - path: "services/protocol-processor-service/src/protocol_processor/graph.py"
      provides: "5-node StateGraph definition"
      contains: "def create_graph"
    - path: "services/protocol-processor-service/src/protocol_processor/trigger.py"
      provides: "Outbox event handler replacing both extraction and grounding triggers"
      contains: "def handle_protocol_uploaded"
    - path: "services/protocol-processor-service/tests/test_graph.py"
      provides: "Graph compilation and mock execution test"
  key_links:
    - from: "services/protocol-processor-service/src/protocol_processor/nodes/ground.py"
      to: "services/protocol-processor-service/src/protocol_processor/tools/terminology_router.py"
      via: "TerminologyRouter.route_entity"
      pattern: "router\\.route_entity"
    - from: "services/protocol-processor-service/src/protocol_processor/nodes/ground.py"
      to: "services/protocol-processor-service/src/protocol_processor/tools/medgemma_decider.py"
      via: "medgemma_decide function call"
      pattern: "medgemma_decide"
    - from: "services/protocol-processor-service/src/protocol_processor/trigger.py"
      to: "services/protocol-processor-service/src/protocol_processor/graph.py"
      via: "get_graph().ainvoke()"
      pattern: "get_graph"
    - from: "services/api-service/src/api_service/main.py"
      to: "services/protocol-processor-service/src/protocol_processor/trigger.py"
      via: "outbox handler registration"
      pattern: "handle_protocol_uploaded"
---

<objective>
Create ground node, persist node, MedGemma decision tool, field mapping tool, 5-node graph assembly, trigger handler, and update api-service outbox wiring to use the consolidated pipeline.

Purpose: Completes the consolidated 5-node pipeline by adding grounding and persistence, wires up the graph, replaces the old 2-service trigger pattern with a single handler, and removes the criteria_extracted outbox event.
Output: Working 5-node graph that compiles, ground node with TerminologyRouter + MedGemma, persist node, trigger handler, and updated api-service outbox configuration.
</objective>

<execution_context>
@/Users/noahdolevelixir/.claude-elixirtrials/get-shit-done/workflows/execute-plan.md
@/Users/noahdolevelixir/.claude-elixirtrials/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/31-terminologyrouter-pipeline-consolidation/31-CONTEXT.md
@.planning/phases/31-terminologyrouter-pipeline-consolidation/31-RESEARCH.md
@.planning/phases/31-terminologyrouter-pipeline-consolidation/31-01-SUMMARY.md
@.planning/phases/31-terminologyrouter-pipeline-consolidation/31-02-SUMMARY.md

# Existing code to adapt from:
@services/grounding-service/src/grounding_service/nodes/medgemma_ground.py
@services/grounding-service/src/grounding_service/nodes/validate_confidence.py
@services/grounding-service/src/grounding_service/prompts/agentic_system.jinja2
@services/grounding-service/src/grounding_service/prompts/agentic_extract.jinja2
@services/grounding-service/src/grounding_service/prompts/agentic_evaluate.jinja2
@services/grounding-service/src/grounding_service/schemas/agentic_actions.py
@services/grounding-service/src/grounding_service/trigger.py
@services/extraction-service/src/extraction_service/trigger.py
@services/api-service/src/api_service/main.py
@services/extraction-service/src/extraction_service/graph.py
@services/grounding-service/src/grounding_service/graph.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ground node, MedGemma decider, field mapper, and persist node</name>
  <files>
    services/protocol-processor-service/src/protocol_processor/nodes/ground.py
    services/protocol-processor-service/src/protocol_processor/nodes/persist.py
    services/protocol-processor-service/src/protocol_processor/tools/medgemma_decider.py
    services/protocol-processor-service/src/protocol_processor/tools/field_mapper.py
    services/protocol-processor-service/src/protocol_processor/prompts/grounding_system.jinja2
    services/protocol-processor-service/src/protocol_processor/prompts/grounding_evaluate.jinja2
  </files>
  <action>
    **Ground node delegates to helper functions per PIPE-02 and user decision.**

    1. Create `tools/medgemma_decider.py`:
       - `async def medgemma_decide(entity: dict, candidates: list[GroundingCandidate], criterion_context: str) -> EntityGroundingResult`:
         - Adapt from `grounding_service/nodes/medgemma_ground.py` agentic loop pattern
         - Send candidates to MedGemma with evaluation prompt
         - MedGemma picks best match and assigns confidence (per user decision: "MedGemma acts as decision-maker, minimum token usage")
         - Machine-readable JSON response parsed into EntityGroundingResult
         - If no candidates provided (e.g., all APIs failed), return result with confidence=0.0 and empty codes
         - Use existing ModelGardenChatModel from `libs/inference/` for MedGemma access

    2. Create `tools/field_mapper.py`:
       - `async def generate_field_mappings(entity: EntityGroundingResult, criterion_text: str) -> list[dict]`:
         - Per user decision: "Generate suggested field_mappings during grounding (ground node)"
         - Per CONTEXT.md specifics: "Criteria should be decomposed per AutoCriteria pattern: separate Entity, Operator, Value, Unit, Time"
         - Per user decision: "MedGemma and Gemini collaborate: Gemini uses MedGemma as medical expert"
         - Use Gemini to generate field mappings from grounded entity + criterion text
         - Return list of `{"entity": str, "relation": str, "value": str, "unit": str | None}` dicts
         - This is a best-effort suggestion — reviewer can edit in UI

    3. Create `nodes/ground.py`:
       - `async def ground_node(state: PipelineState) -> dict`:
         - Parse `state["entities_json"]` to get criteria list
         - For each criterion, extract entities using existing MedGemma agentic extraction pattern (adapt from `medgemma_ground.py`)
         - Route each extracted entity through `TerminologyRouter.route_entity()` to get candidates
         - Pass candidates to `medgemma_decide()` for best-match selection
         - Generate field mappings via `generate_field_mappings()` for each grounded entity
         - **Error accumulation** per user decision: if one entity fails, log error, continue with others. Accumulate errors in `state["errors"]`.
         - **Audit trail** per user decision: for each entity grounding decision, create an AuditLog entry with full details (candidates, selected code, reasoning, API calls). Use `shared.models.AuditLog`.
         - Return `{"grounded_entities_json": json.dumps(results), "errors": accumulated_errors}`
         - Demographics are skipped by TerminologyRouter (returns empty candidates) — ground_node logs this explicitly (GRND-06)

    4. Create `nodes/persist.py`:
       - `async def persist_node(state: PipelineState) -> dict`:
         - Parse `state["grounded_entities_json"]` to get grounding results
         - Create Entity DB records from grounding results (adapt from grounding-service validate_confidence pattern)
         - Store field_mappings in Criteria JSONB `conditions` field (or `field_mappings` if column exists — check shared models)
         - Update protocol status to "pending_review" (final successful state)
         - If `state["errors"]` is non-empty but some entities succeeded, still mark as "pending_review" (partial success is acceptable per user decision)
         - If ALL entities failed, mark protocol as "grounding_failed"
         - Return `{"status": "completed"}` or `{"status": "failed", "error": "All entities failed grounding"}`

    5. Create/adapt grounding prompts:
       - `prompts/grounding_system.jinja2`: Adapt from `grounding_service/prompts/agentic_system.jinja2` — MedGemma system prompt for entity extraction and evaluation
       - `prompts/grounding_evaluate.jinja2`: Adapt from `grounding_service/prompts/agentic_evaluate.jinja2` — evaluation prompt for selecting best candidate from multiple API results. Emphasize machine-readable JSON output and minimum token usage.
  </action>
  <verify>
    - `uv run python -c "from protocol_processor.nodes.ground import ground_node; print('OK')"` succeeds
    - `uv run python -c "from protocol_processor.nodes.persist import persist_node; print('OK')"` succeeds
    - `uv run python -c "from protocol_processor.tools.medgemma_decider import medgemma_decide; print('OK')"` succeeds
    - `uv run python -c "from protocol_processor.tools.field_mapper import generate_field_mappings; print('OK')"` succeeds
    - `uv run ruff check services/protocol-processor-service/` passes
  </verify>
  <done>
    Ground node delegates to TerminologyRouter and MedGemma decider. Error accumulation implemented. Audit trail entries created for all grounding decisions. Persist node commits results and updates protocol status. Field mapping generation integrated into grounding flow.
  </done>
</task>

<task type="auto">
  <name>Task 2: Assemble 5-node graph, create trigger handler, update api-service outbox wiring</name>
  <files>
    services/protocol-processor-service/src/protocol_processor/graph.py
    services/protocol-processor-service/src/protocol_processor/trigger.py
    services/protocol-processor-service/src/protocol_processor/main.py
    services/api-service/src/api_service/main.py
    services/protocol-processor-service/tests/test_graph.py
  </files>
  <action>
    1. Create `graph.py` — 5-node StateGraph with conditional error routing:
       ```python
       from langgraph.graph import StateGraph, START, END
       from .state import PipelineState
       from .nodes.ingest import ingest_node
       from .nodes.extract import extract_node
       from .nodes.parse import parse_node
       from .nodes.ground import ground_node
       from .nodes.persist import persist_node

       def should_continue(state: PipelineState) -> str:
           return "error" if state.get("error") else "continue"

       def create_graph():
           workflow = StateGraph(PipelineState)
           workflow.add_node("ingest", ingest_node)
           workflow.add_node("extract", extract_node)
           workflow.add_node("parse", parse_node)
           workflow.add_node("ground", ground_node)
           workflow.add_node("persist", persist_node)

           workflow.add_edge(START, "ingest")
           # Error routing after ingest, extract, parse
           for source, target in [("ingest", "extract"), ("extract", "parse"), ("parse", "ground")]:
               workflow.add_conditional_edges(source, should_continue, {"continue": target, "error": END})
           # Ground always proceeds to persist (handles errors internally via accumulation)
           workflow.add_edge("ground", "persist")
           workflow.add_edge("persist", END)

           return workflow.compile()
       ```
       - Singleton pattern with `get_graph()` (same as existing services).
       - Ground always proceeds to persist because error accumulation means partial results are persisted.

    2. Create `trigger.py` — unified handler replacing both extraction and grounding triggers:
       - `def handle_protocol_uploaded(payload: dict) -> None`:
         - Adapt from `extraction_service/trigger.py` but invokes the consolidated 5-node graph
         - Constructs initial PipelineState: `{"protocol_id": ..., "file_uri": ..., "title": ..., "batch_id": None, "pdf_bytes": None, "extraction_json": None, "entities_json": None, "grounded_entities_json": None, "status": "processing", "error": None, "errors": []}`
         - Uses `asyncio.run(graph.ainvoke(initial_state))` to bridge sync outbox handler to async graph
         - Include MLflow tracing wrapper (adapt from existing trigger.py pattern)
         - On failure, update protocol status to failed with categorized error reason (adapt `_categorize_extraction_error` and `_categorize_grounding_error` from both triggers into one `_categorize_pipeline_error`)

    3. Create `main.py` — service entrypoint (optional, for standalone running):
       - Minimal module that exposes `get_graph()` for import by api-service

    4. **Update `services/api-service/src/api_service/main.py`**:
       - Replace old trigger imports:
         - Remove: `from extraction_service.trigger import handle_protocol_uploaded`
         - Remove: `from grounding_service.trigger import handle_criteria_extracted`
         - Add: `from protocol_processor.trigger import handle_protocol_uploaded`
       - Update outbox handlers dict:
         - Remove: `"criteria_extracted": [handle_criteria_extracted]`
         - Keep: `"protocol_uploaded": [handle_protocol_uploaded]` (but now using new import)
       - This is the PIPE-03 requirement: criteria_extracted outbox removed, protocol_uploaded retained.

    5. Create `tests/test_graph.py`:
       - Test that `create_graph()` compiles without error
       - Test that compiled graph has 5 nodes: ingest, extract, parse, ground, persist
       - Test graph structure: verify edges exist (START→ingest, etc.)
       - Use mock state to verify graph accepts PipelineState shape
       - This verifies state flow before real grounding integration (Phase 31 success criterion 9).
  </action>
  <verify>
    - `uv run python -c "from protocol_processor.graph import create_graph; g = create_graph(); print(f'Nodes: {len(g.nodes)}'); print('OK')"` — prints "Nodes: 5" (or similar count including __start__/__end__)
    - `uv run pytest services/protocol-processor-service/tests/test_graph.py -v` — all tests pass
    - `uv run ruff check services/protocol-processor-service/ services/api-service/` — clean
    - Verify `api_service/main.py` no longer imports from `extraction_service.trigger` or `grounding_service.trigger`
    - Verify `api_service/main.py` no longer has `"criteria_extracted"` in outbox handlers
  </verify>
  <done>
    5-node graph compiles and routes correctly. Trigger handler invokes consolidated pipeline on protocol_uploaded. api-service updated to use new trigger (criteria_extracted outbox removed). Graph compilation test passes. Pipeline can be run end-to-end with mock grounding.
  </done>
</task>

</tasks>

<verification>
1. `uv run pytest services/protocol-processor-service/ -v` — all tests pass (routing tests from plan 01 + graph tests)
2. `uv run ruff check services/protocol-processor-service/ services/api-service/` — clean
3. Graph has exactly 5 user nodes: ingest, extract, parse, ground, persist
4. api-service/main.py imports from protocol_processor.trigger (not extraction_service.trigger or grounding_service.trigger)
5. No references to criteria_extracted outbox in protocol-processor-service code
6. Ground node delegates to TerminologyRouter and medgemma_decide helper functions (not inline logic)
7. AuditLog entries are created for grounding decisions
</verification>

<success_criteria>
- 5-node LangGraph pipeline compiles: ingest→extract→parse→ground→persist
- Ground node uses TerminologyRouter for routing + MedGemma for decision (delegation pattern)
- Error accumulation: partial entity failures don't fail entire batch
- All grounding decisions logged to AuditLog
- criteria_extracted outbox event removed from api-service
- protocol_uploaded outbox retained and triggers consolidated pipeline
- Field mappings generated during grounding
- Graph compilation test passes
</success_criteria>

<output>
After completion, create `.planning/phases/31-terminologyrouter-pipeline-consolidation/31-03-SUMMARY.md`
</output>
